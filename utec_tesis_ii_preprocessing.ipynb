{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10055469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pandas as pd\n",
    "from spellpy import spell\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbabbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-03 02:32:18,627][INFO]: Parsing file: ./data/banking_simulation/banking_simulation_normal.log\n",
      "[2023-11-03 02:32:18,760][INFO]: Loaded 36.9% of log lines.\n",
      "[2023-11-03 02:32:18,856][INFO]: Loaded 73.7% of log lines.\n",
      "[2023-11-03 02:32:18,927][INFO]: Loaded 100.0% of log lines.\n",
      "[2023-11-03 02:32:18,945][INFO]: load_data() finished!\n",
      "[2023-11-03 02:32:18,952][INFO]: Load objects done, lastestLineId: 87121\n",
      "[2023-11-03 02:32:19,240][INFO]: Processed 36.9% of log lines.\n",
      "[2023-11-03 02:32:19,511][INFO]: Processed 73.7% of log lines.\n",
      "[2023-11-03 02:32:19,722][INFO]: Processed 100.0% of log lines.\n",
      "[2023-11-03 02:32:20,438][INFO]: Output parse file\n",
      "[2023-11-03 02:32:20,660][INFO]: lastestLindId: 87121\n",
      "[2023-11-03 02:32:21,798][INFO]: rootNodePath: ./data/banking_simulation/result/rootNode.pkl\n",
      "[2023-11-03 02:32:21,800][INFO]: logCluLPath: ./data/banking_simulation/result/logCluL.pkl\n",
      "[2023-11-03 02:32:21,802][INFO]: Store objects done.\n",
      "[2023-11-03 02:32:21,802][INFO]: Parsing done. [Time taken: 0:00:03.174536]\n",
      "[2023-11-03 02:32:21,804][INFO]: Parsing file: ./data/banking_simulation/banking_simulation_abnormal.log\n",
      "[2023-11-03 02:32:21,837][INFO]: Loaded 100.0% of log lines.\n",
      "[2023-11-03 02:32:21,847][INFO]: load_data() finished!\n",
      "[2023-11-03 02:32:21,853][INFO]: Load objects done, lastestLineId: 114242\n",
      "[2023-11-03 02:32:21,943][INFO]: Processed 100.0% of log lines.\n",
      "[2023-11-03 02:32:22,034][INFO]: Output parse file\n",
      "[2023-11-03 02:32:22,211][INFO]: lastestLindId: 114242\n",
      "[2023-11-03 02:32:22,740][INFO]: rootNodePath: ./data/banking_simulation/result/rootNode.pkl\n",
      "[2023-11-03 02:32:22,741][INFO]: logCluLPath: ./data/banking_simulation/result/logCluL.pkl\n",
      "[2023-11-03 02:32:22,743][INFO]: Store objects done.\n",
      "[2023-11-03 02:32:22,744][INFO]: Parsing done. [Time taken: 0:00:00.939275]\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"./data/banking_simulation\"\n",
    "output_dir = \"./data/banking_simulation/result\"\n",
    "\n",
    "# 2023-11-03 01:46:40 - IP: 152.237.212.155 - Location: Berlin, Germany - Device ID: D7487C - User: ryan - Failed login attempt from user ryan.\n",
    "log_format = \"<Date> <Time> - IP: <IP> - Location: <Location> - Device ID: <DeviceID> - User: <User> - <Content>\"\n",
    "log_main = \"banking_simulation\"\n",
    "tau = 0.5\n",
    "\n",
    "def preprocess():\n",
    "    parser = spell.LogParser(\n",
    "        indir=input_dir,\n",
    "        outdir=output_dir,\n",
    "        log_format=log_format,\n",
    "        logmain=log_main,\n",
    "        tau=tau\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    log_files = [\n",
    "        'banking_simulation_normal.log',\n",
    "        'banking_simulation_abnormal.log'\n",
    "    ]\n",
    "    for log_name in log_files:\n",
    "        parser.parse(log_name)\n",
    "\n",
    "    df_normal = pd.read_csv(f'{output_dir}/banking_simulation_normal.log_structured.csv')\n",
    "    df_abnormal = pd.read_csv(f'{output_dir}/banking_simulation_abnormal.log_structured.csv')\n",
    "\n",
    "    return df_normal, df_abnormal\n",
    "\n",
    "df_normal, df_abnormal = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9446321c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineId</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>IP</th>\n",
       "      <th>Location</th>\n",
       "      <th>DeviceID</th>\n",
       "      <th>User</th>\n",
       "      <th>Content</th>\n",
       "      <th>EventId</th>\n",
       "      <th>EventTemplate</th>\n",
       "      <th>ParameterList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87122</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>02:13:05</td>\n",
       "      <td>66.214.242.20</td>\n",
       "      <td>New York, USA</td>\n",
       "      <td>3C00BA</td>\n",
       "      <td>jack</td>\n",
       "      <td>Failed login attempt from user jack.</td>\n",
       "      <td>6e63e1cc</td>\n",
       "      <td>&lt;*&gt; login attempt from user &lt;*&gt;</td>\n",
       "      <td>['Failed', 'jack']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87123</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>02:18:05</td>\n",
       "      <td>66.214.242.20</td>\n",
       "      <td>New York, USA</td>\n",
       "      <td>3C00BA</td>\n",
       "      <td>jack</td>\n",
       "      <td>Successful login attempt from user jack.</td>\n",
       "      <td>6e63e1cc</td>\n",
       "      <td>&lt;*&gt; login attempt from user &lt;*&gt;</td>\n",
       "      <td>['Successful', 'jack']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87124</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>02:13:05</td>\n",
       "      <td>193.179.221.227</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>AAC6A9</td>\n",
       "      <td>grace</td>\n",
       "      <td>Failed login attempt from user grace.</td>\n",
       "      <td>6e63e1cc</td>\n",
       "      <td>&lt;*&gt; login attempt from user &lt;*&gt;</td>\n",
       "      <td>['Failed', 'grace']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87125</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>02:18:05</td>\n",
       "      <td>193.179.221.227</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>AAC6A9</td>\n",
       "      <td>grace</td>\n",
       "      <td>Successful login attempt from user grace.</td>\n",
       "      <td>6e63e1cc</td>\n",
       "      <td>&lt;*&gt; login attempt from user &lt;*&gt;</td>\n",
       "      <td>['Successful', 'grace']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87126</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>02:13:05</td>\n",
       "      <td>120.43.83.79</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>7E9E7E</td>\n",
       "      <td>penelope</td>\n",
       "      <td>Successful login attempt from user penelope.</td>\n",
       "      <td>6e63e1cc</td>\n",
       "      <td>&lt;*&gt; login attempt from user &lt;*&gt;</td>\n",
       "      <td>['Successful', 'penelope']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LineId        Date      Time               IP       Location DeviceID  \\\n",
       "0   87122  2023-11-03  02:13:05    66.214.242.20  New York, USA   3C00BA   \n",
       "1   87123  2023-11-03  02:18:05    66.214.242.20  New York, USA   3C00BA   \n",
       "2   87124  2023-11-03  02:13:05  193.179.221.227  Mumbai, India   AAC6A9   \n",
       "3   87125  2023-11-03  02:18:05  193.179.221.227  Mumbai, India   AAC6A9   \n",
       "4   87126  2023-11-03  02:13:05     120.43.83.79     London, UK   7E9E7E   \n",
       "\n",
       "       User                                       Content   EventId  \\\n",
       "0      jack          Failed login attempt from user jack.  6e63e1cc   \n",
       "1      jack      Successful login attempt from user jack.  6e63e1cc   \n",
       "2     grace         Failed login attempt from user grace.  6e63e1cc   \n",
       "3     grace     Successful login attempt from user grace.  6e63e1cc   \n",
       "4  penelope  Successful login attempt from user penelope.  6e63e1cc   \n",
       "\n",
       "                     EventTemplate               ParameterList  \n",
       "0  <*> login attempt from user <*>          ['Failed', 'jack']  \n",
       "1  <*> login attempt from user <*>      ['Successful', 'jack']  \n",
       "2  <*> login attempt from user <*>         ['Failed', 'grace']  \n",
       "3  <*> login attempt from user <*>     ['Successful', 'grace']  \n",
       "4  <*> login attempt from user <*>  ['Successful', 'penelope']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b18df4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27121, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a66265a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Successful <*> of <*> units. <*>    18243\n",
       "<*> login attempt from user <*>      8878\n",
       "Name: EventTemplate, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal['EventTemplate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4de9af70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73d80640    18243\n",
       "6e63e1cc     8878\n",
       "Name: EventId, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal['EventId'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d3febd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alice        659\n",
       "oscar        636\n",
       "leah         636\n",
       "daniel       624\n",
       "quinn        617\n",
       "bob          604\n",
       "victor       603\n",
       "katherine    603\n",
       "zane         601\n",
       "ethan        601\n",
       "david        600\n",
       "sophia       596\n",
       "ella         595\n",
       "jack         592\n",
       "mason        591\n",
       "lily         588\n",
       "ivy          587\n",
       "james        586\n",
       "lucy         581\n",
       "emma         578\n",
       "eve          576\n",
       "zoe          574\n",
       "ava          574\n",
       "oliver       572\n",
       "olivia       572\n",
       "aiden        572\n",
       "grace        570\n",
       "liam         569\n",
       "xander       569\n",
       "hannah       565\n",
       "noah         560\n",
       "sophie       559\n",
       "ursula       557\n",
       "chloe        557\n",
       "willow       557\n",
       "penelope     556\n",
       "nora         556\n",
       "jacob        555\n",
       "thomas       555\n",
       "mia          554\n",
       "charlie      547\n",
       "ryan         547\n",
       "benjamin     543\n",
       "frank        542\n",
       "yasmine      532\n",
       "harper       530\n",
       "amelia       523\n",
       "Name: User, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal['User'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f438fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal_train, df_normal_test = train_test_split(df_normal, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5150ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def group_logs_by_datetime(df, event_id_map):\n",
    "    df[\"Datetime\"] = pd.to_datetime(df[\"Date\"] + \" \" + df[\"Time\"])\n",
    "    df = df[[\"Datetime\", \"EventId\"]]\n",
    "    df[\"EventId\"] = df[\"EventId\"].apply(lambda e: event_id_map[e] if event_id_map.get(e) else -1)\n",
    "    deeplog_df = df.set_index(\"Datetime\").resample(\"1min\").apply(lambda arr: list(arr)).reset_index()\n",
    "    return deeplog_df\n",
    "\n",
    "\n",
    "def save_deeplog_df(filename, df):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for event_id_list in df[\"EventId\"]:\n",
    "            for event_id in event_id_list:\n",
    "                f.write(str(event_id) + \" \")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "def generate_log_key_sequences(df_normal_train, df_normal_test, df_abnormal):\n",
    "    event_id_map = {}\n",
    "    for index, event_id in enumerate(df_normal_train[\"EventId\"].unique(), 1):\n",
    "        event_id_map[event_id] = index\n",
    "\n",
    "    print(f\"Número de log keys únicos {len(event_id_map)}\")\n",
    "\n",
    "    print(event_id_map)\n",
    "    deeplog_train_df = group_logs_by_datetime(df_normal_train, event_id_map)\n",
    "    save_deeplog_df(\"train\", deeplog_train_df)\n",
    "\n",
    "    deeplog_test_normal = group_logs_by_datetime(df_normal_test, event_id_map)\n",
    "    save_deeplog_df(\"test_normal\", deeplog_test_normal)\n",
    "\n",
    "    deeplog_test_abnormal = group_logs_by_datetime(df_abnormal, event_id_map)\n",
    "    save_deeplog_df(\"test_abnormal\", deeplog_test_abnormal)\n",
    "\n",
    "generate_log_key_sequences(df_normal_train, df_normal_test, df_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b8d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "NUM_CLASSES = 1143\n",
    "NUM_CANDIDATES = 114\n",
    "EPOCHS = 35\n",
    "WINDOW_SIZE =  3\n",
    "BATCH_SIZE = 64\n",
    "SEED = 1\n",
    "\n",
    "INPUT_SIZE = 1\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2751d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generate:\n",
    "    def __init__(self):\n",
    "        self.file = None\n",
    "  \n",
    "    def generate(self, filename, window_size):\n",
    "        num_sessions = 0\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "\n",
    "        line = self.init_line(filename)\n",
    "        while line:\n",
    "            line = tuple(map(lambda n: n - 1, map(int, line.strip().split())))\n",
    "            for i in range(len(line) - window_size):\n",
    "                inputs.append(line[i:i+window_size])\n",
    "                outputs.append(line[i+window_size])\n",
    "            line = self.readline()\n",
    "            num_sessions += 1\n",
    "\n",
    "        print('Number of session({}): {}'.format(filename, len(inputs)))\n",
    "        print('Number of seqs({}): {}'.format(filename, len(inputs)))\n",
    "\n",
    "        dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float), torch.tensor(outputs))\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def init_line(self, filename):\n",
    "        f = open(filename, 'r')\n",
    "        self.file = f\n",
    "        line = self.file.readline()\n",
    "        return line\n",
    "\n",
    "    def readline(self):\n",
    "        line = self.file.readline()\n",
    "        return line\n",
    "\n",
    "def get_train_data_loader():\n",
    "    print(\"Get train data loader\")\n",
    "    generate = Generate()\n",
    "    sequence_dataset = generate.generate(filename=\"train\", window_size=WINDOW_SIZE)\n",
    "    dataloader = DataLoader(sequence_dataset, batch_size=BATCH_SIZE, shuffle=None, sampler=None)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def save_model(model, model_dir):\n",
    "    print(\"Saving the model.\")\n",
    "    path = os.path.join(model_dir, 'model.pth')\n",
    "    torch.save(model.cpu().state_dict(), path)\n",
    "    model_info_path = os.path.join(model_dir, 'model_info.pth')\n",
    "    with open(model_info_path, 'wb') as f:\n",
    "        model_info = {\n",
    "            'input_size': INPUT_SIZE,\n",
    "            'hidden_size': HIDDEN_SIZE,\n",
    "            'num_layers': NUM_LAYERS,\n",
    "            'num_classes': NUM_CLASSES,\n",
    "            'num_candidates': NUM_CANDIDATES,\n",
    "            'window_size': WINDOW_SIZE,\n",
    "        }\n",
    "        torch.save(model_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd63ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        h0 = torch.zeros(self.num_layers, input.size(0), self.hidden_size).to(input.device)\n",
    "        c0 = torch.zeros(self.num_layers, input.size(0), self.hidden_size).to(input.device)\n",
    "        out, _ = self.lstm(input, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e888d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "torch.manual_seed(SEED)\n",
    "train_loader = get_train_data_loader()\n",
    "\n",
    "print(\"processed {}/{} ({:.0f}%) of traind data\".format(\n",
    "    len(train_loader.sampler), len(train_loader.dataset),\n",
    "    100. * len(train_loader.sampler) / len(train_loader.dataset)\n",
    "))\n",
    "\n",
    "model = Model(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for seq, label in train_loader:\n",
    "        seq = seq.clone().detach().view(-1, WINDOW_SIZE, INPUT_SIZE).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(seq)\n",
    "        loss = criterion(output, label.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print('Epoch [{}/{}], Train_loss: {}'.format(\n",
    "        epoch, EPOCHS, round(train_loss/len(train_loader.dataset), 4)\n",
    "    ))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ea1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c26b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed77a57",
   "metadata": {},
   "source": [
    "## Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95477284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir):\n",
    "    print(\"Loading the model.\")\n",
    "\n",
    "    model_info = {}\n",
    "    with open(os.path.join(model_dir, \"model_info.pth\"), \"rb\") as f:\n",
    "        model_info = torch.load(f)\n",
    "\n",
    "    print(\"model_info: {}\".format(model_info))\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Current device: {}\".format(device))\n",
    "\n",
    "    model = Model(\n",
    "        input_size=model_info[\"input_size\"],\n",
    "        hidden_size=model_info[\"hidden_size\"],\n",
    "        num_layers=model_info[\"num_layers\"],\n",
    "        num_classes=model_info[\"num_classes\"],\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(model_dir, \"model.pth\"), \"rb\") as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "\n",
    "    return {\n",
    "        \"model\": model.to(device),\n",
    "        \"window_size\": model_info[\"window_size\"],\n",
    "        \"input_size\": model_info[\"input_size\"],\n",
    "        \"num_candidates\": model_info[\"num_candidates\"]\n",
    "    }\n",
    "\n",
    "def predict(input_data, model_info):\n",
    "    line = input_data['line']\n",
    "    num_candidates = model_info['num_candidates']\n",
    "    input_size = model_info['input_size']\n",
    "    window_size = model_info['window_size']\n",
    "    model = model_info['model']\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    predict_cnt = 0\n",
    "    anomaly_cnt = 0\n",
    "    predict_list = [0] * len(line)\n",
    "    for i in range(len(line) - window_size):\n",
    "        seq = line[i:i + window_size]\n",
    "        label = line[i + window_size]\n",
    "        seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
    "        label = torch.tensor(label).view(-1).to(device)\n",
    "        output = model(seq)\n",
    "        predict = torch.argsort(output, 1)[0][-num_candidates:]\n",
    "        if label not in predict:\n",
    "            anomaly_cnt += 1\n",
    "            predict_list[i + window_size] = 1\n",
    "            predict_cnt += 1\n",
    "    return {'anomaly_cnt': anomaly_cnt, 'predict_cnt': predict_cnt, 'predict_list': predict_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46155b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_info = load_model(\"./model\")\n",
    "test_abnormal_list = []\n",
    "with open('test_abnormal', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = list(map(lambda n: n - 1, map(int, line.strip().split())))\n",
    "        response = predict(json.loads(json.dumps({\"line\": line})), model_info)\n",
    "        test_abnormal_list.append(response)\n",
    "\n",
    "test_normal_list = []\n",
    "with open('test_normal', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = list(map(lambda n: n - 1, map(int, line.strip().split())))\n",
    "        response = predict(json.loads(json.dumps({\"line\": line})), model_info)\n",
    "        test_normal_list.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0078a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "threshold = 25\n",
    "abnormal_has_anomaly = [1 if t[\"anomaly_cnt\"] > threshold else 0 for t in test_abnormal_list]\n",
    "abnormal_cnt_anomaly = [t[\"anomaly_cnt\"] for t in test_abnormal_list]\n",
    "abnormal_predict = []\n",
    "for test_abnormal in test_abnormal_list:\n",
    "    abnormal_predict += test_abnormal[\"predict_list\"]\n",
    "\n",
    "normal_has_anomaly = [1 if t['anomaly_cnt'] > threshold else 0 for t in test_normal_list]\n",
    "normal_cnt_anomaly = [t['anomaly_cnt'] for t in test_normal_list]\n",
    "normal_predict = []\n",
    "for test_normal in test_normal_list:\n",
    "    normal_predict += test_normal['predict_list']\n",
    "\n",
    "ground_truth = [1]*len(abnormal_has_anomaly) + [0]*len(normal_has_anomaly)\n",
    "predict = abnormal_has_anomaly + normal_has_anomaly\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "accu = 0\n",
    "for p, t in zip(predict, ground_truth):\n",
    "    if p == t:\n",
    "        accu += 1\n",
    "\n",
    "    if p == 1 and t == 1:\n",
    "        TP += 1\n",
    "    elif p == 1 and t == 0:\n",
    "        FP += 1\n",
    "    elif p == 0 and t == 1:\n",
    "        FN += 1\n",
    "    else:\n",
    "        TN += 1\n",
    "\n",
    "print(f'thres: {threshold}')\n",
    "print(f'TP: {TP}')\n",
    "print(f'FP: {FP}')\n",
    "print(f'TN: {TN}')\n",
    "print(f'FN: {FN}')\n",
    "\n",
    "accuracy = accu / len(predict)\n",
    "precision = TP / (TP + FP) if (TP + FP) else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) else 0\n",
    "F1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "print(f'accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {F1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
